[
  {
    "question": "The question asks to use gpt-3.5-turbo-0125 model but the ai-proxy provided by Anand sir only supports gpt-4o-mini. So should we just use gpt-4o-mini or use the OpenAI API for gpt3.5 turbo?",
    "answers": [
      "You must use gpt-3.5-turbo-0125, even if the AI Proxy only supports gpt-4o-mini. Use the OpenAI API directly for this question."
    ],
    "links": [
      {
        "url": "https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939/4",
        "text": "Use the model that’s mentioned in the question."
      },
      {
        "url": "https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939/3",
        "text": "My understanding is that you just have to use a tokenizer, similar to what Prof. Anand used, to get the number of tokens and multiply that by the given rate."
      },
      {
        "url" : "https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939/2",
        "text" : "I tried gpt-3.5-turbo-0125 with python’s tiktoken library , I got a different value for prompt token compared gpt-4o-mini from the proxy api."
      },
      {
        "url" : "https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939/6?u=22f1000169",
        "text" : "https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939/6"
      }
    ]
  }
]
